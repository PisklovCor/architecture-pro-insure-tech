# Архитектурные решения для InsureTech

## 1. Стратегия масштабирования и отказоустойчивости

### Выбор стратегии: Горизонтальное масштабирование

**Решение:** Использование горизонтального масштабирования с несколькими зонами доступности.

**Обоснование:**
- Вертикальное масштабирование имеет ограничения по максимальным ресурсам одной машины
- Горизонтальное масштабирование обеспечивает лучшую отказоустойчивость
- Соответствие требованиям RTO 45 мин и RPO 15 мин требует географического распределения
- Обеспечение одинакового времени загрузки для всех регионов требует размещения серверов в разных географических точках

### Использование дополнительных зон безопасности

**Решение:** Развертывание в минимум 2 зонах доступности в разных регионах РФ (Москва и Екатеринбург).

**Обоснование:**
- Требования RTO 45 мин и RPO 15 мин требуют географического распределения
- Доступность 99.9% обеспечивается наличием резервной зоны
- Покрытие всех часовых поясов РФ
- Снижение задержек для пользователей из разных регионов

## 2. Конфигурация развертывания в Kubernetes

### Выбор: Независимые кластеры в каждой зоне

**Решение:** Использование независимых Kubernetes кластеров в каждой зоне доступности.

**Обоснование:**
1. **Полная изоляция зон** - сбой одного кластера не влияет на другой, что критично для соответствия RTO 45 мин
2. **Автономность работы** - каждая зона может работать независимо при потере связи между зонами
3. **Независимое масштабирование** - каждая зона масштабируется в зависимости от локальной нагрузки
4. **Упрощение управления** - нет зависимости от сетевого соединения между зонами для работы кластера
5. **Безопасность** - изоляция снижает риск каскадных сбоев

**Альтернатива (растянутый кластер) была отклонена по причинам:**
- Требует стабильного сетевого соединения между зонами
- Увеличивает сложность управления
- Может привести к split-brain проблемам
- Не обеспечивает достаточную изоляцию для требований RTO

### Конфигурация кластеров:
- **Auto-scaling включен** - автоматическое масштабирование подов в зависимости от нагрузки
- **Минимум 3 реплики** приложения в каждой зоне для отказоустойчивости
- **HPA (Horizontal Pod Autoscaler)** для автоматического масштабирования на основе метрик CPU и памяти
- **Liveness и Readiness Probes** для контроля здоровья подов

## 3. Балансировка нагрузки

### Многоуровневая балансировка

**Уровень 1: Глобальный Application Load Balancer**
- **Yandex Application Load Balancer** с географической маршрутизацией
- Распределение трафика между зонами на основе:
  - Географического местоположения пользователя
  - Здоровья зон (health checks)
  - Нагрузки на зоны
- Обеспечивает одинаковое время загрузки для пользователей из разных регионов

**Уровень 2: Regional Load Balancer**
- Балансировщик в каждой зоне для распределения трафика между подами
- Health Check на эндпоинте `/health`
- Проверка доступности каждые 5-10 секунд

**Уровень 3: Kubernetes Service**
- Внутрикластерная балансировка через Kubernetes Service
- Health Checks:
  - **Liveness Probe** - проверка, что контейнер работает (перезапуск при сбое)
  - **Readiness Probe** - проверка готовности принимать трафик

### Health Checks на всех уровнях:

1. **ALB → Regional LB**: Проверка доступности регионального балансировщика
2. **Regional LB → Kubernetes Service**: Проверка эндпоинта `/health` приложения
3. **Kubernetes → Pods**: Liveness и Readiness Probes
4. **Application → Database**: Проверка подключения к БД

## 4. Фейловер-стратегия

### Active-Active конфигурация

**Решение:** Active-Active конфигурация с автоматическим failover.

**Описание:**
- Обе зоны обрабатывают трафик одновременно
- Глобальный ALB распределяет трафик между зонами
- При недоступности одной зоны (по результатам health checks) весь трафик автоматически перенаправляется на доступную зону
- Время переключения: < 1 минута (намного меньше RTO 45 мин)

**Механизм failover:**
1. **Мониторинг** - Yandex Monitoring отслеживает состояние всех компонентов
2. **Обнаружение сбоя** - при недоступности зоны (по health checks)
3. **Автоматическое переключение** - ALB исключает недоступную зону из балансировки
4. **Уведомления** - отправка алертов команде для ручного вмешательства при необходимости

**Обеспечение RTO 45 мин:**
- Автоматический failover происходит за секунды
- Автономность зон позволяет работать без зависимости от другой зоны
- Резервная зона всегда готова принимать трафик

## 5. Конфигурация базы данных

### Архитектура БД

**Решение:** Yandex Managed PostgreSQL с синхронной репликацией между зонами.

### Репликация данных

**Конфигурация:**
- **Master** в зоне 1 (Москва) - обработка запросов на запись
- **Replica** в зоне 2 (Екатеринбург) - синхронная репликация
- **Синхронная репликация** обеспечивает RPO 15 мин (данные реплицируются в реальном времени)

**Преимущества синхронной репликации:**
- Минимальная потеря данных при сбое (RPO близок к 0)
- Возможность быстрого переключения на реплику
- Консистентность данных между зонами

**Механизм репликации:**
- Использование встроенных механизмов PostgreSQL (Streaming Replication)
- Yandex Managed PostgreSQL автоматически управляет репликацией
- Мониторинг лага репликации

### Резервное копирование

**Конфигурация:**
- **Автоматические бэкапы** каждые 15 минут в Yandex Object Storage
- Соответствие требованию RPO 15 мин
- Хранение бэкапов в отдельном регионе для дополнительной защиты
- Политика хранения: 7 дней ежедневных, 4 недели еженедельных, 12 месяцев ежемесячных

**Процесс восстановления:**
- Восстановление из бэкапа занимает < 30 минут
- Автоматическое восстановление при сбое master на реплику
- Ручное восстановление из бэкапа при необходимости

### Шардирование БД

**Решение: Шардирование НЕ требуется**

**Обоснование:**
- Объем данных: 50 GB - небольшой объем для современных БД
- PostgreSQL может эффективно обрабатывать такой объем на одной инстанции
- Шардирование добавит сложность без необходимости
- Синхронная репликация обеспечивает достаточную производительность и отказоустойчивость

**Когда потребуется шардирование:**
- При росте объема данных > 500 GB
- При росте нагрузки на запись, которую не может обработать одна инстанция
- При необходимости географического распределения данных по регионам

### Использование Yandex Managed PostgreSQL

**Преимущества:**
- Автоматическое управление репликацией
- Автоматические бэкапы
- Мониторинг и алертинг
- Автоматические обновления и патчи
- Упрощенное управление инфраструктурой БД

## 6. Дополнительные компоненты

### CDN (Content Delivery Network)

**Yandex Cloud CDN** для:
- Кэширования статического контента (CSS, JS, изображения)
- Снижения нагрузки на приложение
- Обеспечения одинаковой скорости загрузки для пользователей из разных регионов
- Снижения задержек за счет размещения контента ближе к пользователям

### Мониторинг и алертинг

**Yandex Monitoring** для:
- Мониторинга состояния всех компонентов системы
- Отслеживания метрик производительности
- Автоматического обнаружения проблем
- Алертинга команды при критических событиях
- Автоматического failover при сбоях

## Итоговая архитектура

### Компоненты:
1. **Глобальный Application Load Balancer** - балансировка между зонами
2. **2 зоны доступности** - Москва и Екатеринбург
3. **2 независимых Kubernetes кластера** - по одному в каждой зоне
4. **Application Pods** - минимум 3 реплики в каждой зоне с auto-scaling
5. **PostgreSQL Master-Replica** - синхронная репликация между зонами
6. **Object Storage** - автоматические бэкапы каждые 15 минут
7. **CDN** - кэширование статики
8. **Monitoring** - мониторинг и автоматический failover

### Соответствие требованиям:

- ✅ **RTO 45 мин** - обеспечивается автономностью зон и автоматическим failover
- ✅ **RPO 15 мин** - синхронная репликация + бэкапы каждые 15 минут
- ✅ **Доступность 99.9%** - две независимые зоны с автоматическим переключением
- ✅ **Одинаковое время загрузки** - CDN + географическое распределение серверов
- ✅ **Работа 24/7** - активные зоны в разных часовых поясах
- ✅ **Масштабирование** - горизонтальное масштабирование с auto-scaling

